{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fFfUQuEVkAn_"
      ],
      "authorship_tag": "ABX9TyM0SKsV4ydga86Ew1fz+zD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blantranderozari/Blantranderozari/blob/main/Draft_Tugas_Proyek_Akhir_Dicoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyek Akhir Dicoding Module: Belajar Machine Learning untuk Pemula\n",
        "oleh Antonius Blantran de Rozari"
      ],
      "metadata": {
        "id": "jTwf4oIh7WuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kriteria\n",
        "\n",
        "* ~Dataset yang dipakai haruslah dataset berikut : rockpaperscissors, atau gunakan link ini pada wget command: https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip.~\n",
        "* ~Dataset harus dibagi menjadi train set dan validation set~.\n",
        "* ~Ukuran validation set harus 40% dari total dataset (data training memiliki 1314 sampel, dan data validasi sebanyak 874 sampel)~.\n",
        "* ~Harus mengimplementasikan augmentasi gambar~.\n",
        "* ~Menggunakan image data generator~.\n",
        "* Model harus menggunakan model sequential.\n",
        "* Pelatihan model tidak melebihi waktu 30 menit.\n",
        "* ~Program dikerjakan pada Google Colaboratory.~\n",
        "* Akurasi dari model minimal 85%.\n",
        "* Dapat memprediksi gambar yang diunggah ke Colab\n",
        "* Menambahkan data diri (sesuai profil Dicoding) pada submission/project yang dikirimkan."
      ],
      "metadata": {
        "id": "fFfUQuEVkAn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pilihan pertama:\n",
        "1. Mulai dari awal sama sekali\n",
        "2. Mulai dengan best weight result dan lanjutkan training\n",
        "3. Langsung deteksi\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2KX84_PybLah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aktifkan GPU\n"
      ],
      "metadata": {
        "id": "3kRvbkpq6u4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gunakan GPU yang disediakan oleh Google Colab\n",
        "import tensorflow as tf \n",
        "print(f\"Versi tensorflow {tf.__version__}\")\n",
        "\n",
        "if (tf.config.list_physical_devices('GPU')):\n",
        "  print(f\"Tersedia GPU sejumlah {len(tf.config.list_physical_devices('GPU'))} dengan nama {tf.test.gpu_device_name()}\")\n",
        "else:\n",
        "  print(\"GPU tidak diaktifkan atau belum tersedia saat ini\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0u-SwYH11HS",
        "outputId": "11dfcc76-cd32-494d-f6de-615c905966eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versi tensorflow 2.9.2\n",
            "Tersedia GPU sejumlah 1 dengan name /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
        "#!unzip rockpaperscissors.zip"
      ],
      "metadata": {
        "id": "r9dkd5SkerLS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unduh data "
      ],
      "metadata": {
        "id": "NpJVNnyEh8so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathlib2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8FMwKlavlUG",
        "outputId": "b88c659e-d9a3-49ac-9e3e-85059e59cd1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pathlib2\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2) (1.15.0)\n",
            "Installing collected packages: pathlib2\n",
            "Successfully installed pathlib2-2.3.7.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from pathlib2 import Path\n",
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "url_data = \"https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\"\n",
        "base_dir = get_file(origin=url_data, cache_dir=\"/tmp\", \n",
        "                    archive_format='auto', extract=True)\n",
        "\n",
        "base_dir = Path(base_dir)\n",
        "base_dir = base_dir.with_suffix('')\n",
        "base_dir = base_dir / 'rps-cv-images'"
      ],
      "metadata": {
        "id": "g3YNcs0xvL3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4119e077-2d89-40ea-e0dd-5ca955b1ba9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "322873683/322873683 [==============================] - 42s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisasi Data \n",
        "**COMPLETE THIS!**\n",
        "\n",
        "Dataset menyimpan 2.188 citra yang terbagi atas 3 kategori yaitu: 'Rock' (726 citra), 'Paper' (710 citra) and 'Scissors' (752 citra) dalam format png berukuran 300 x 200 pixels."
      ],
      "metadata": {
        "id": "vBrzdsmqq6Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_dir)\n",
        "\n",
        "jumlah_citra = len(list(base_dir.glob('**/*.png')))\n",
        "print(f\"Jumlah Citra Seluruhnya {jumlah_citra}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY34Jh_GPPxJ",
        "outputId": "6b69de7e-8c78-4dcd-bd4b-eb8334874288"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/datasets/rockpaperscissors/rps-cv-images\n",
            "Jumlah Citra Seluruhnya 2188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentasi Data Citra\n",
        "Setiap kelas citra terbagi menjadi tiga kategori sesuai dengan nama folder-nya:"
      ],
      "metadata": {
        "id": "DWRw3KaZrmkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/datasets/rockpaperscissors/paper\n",
        "!rm -rf /tmp/datasets/rockpaperscissors/rock\n",
        "!rm -rf /tmp/datasets/rockpaperscissors/scissors\n",
        "!ls /tmp/datasets/rockpaperscissors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6IknlMK265h",
        "outputId": "519c4018-0436-415f-958f-c92005bdb048"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README_rpc-cv-images.txt  rps-cv-images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_latihan = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip = True, # mungkin harus mencoba vertical_flip untuk melihat pengaruhnya\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 45,    # nominal 20 derajat\n",
        "    shear_range = 0.5,       # nominal 0.2 derajat\n",
        "    validation_split = 0.4  # porsi data untuk validasi \n",
        ")\n",
        "\n",
        "#data_validasi = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#    rescale = 1./255.\n",
        "#)"
      ],
      "metadata": {
        "id": "L8HL4AYBiP2E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator Data Citra\n",
        "untuk pelatihan dan validasi "
      ],
      "metadata": {
        "id": "lKFLbjNFka9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterasi untuk membuat data citra untuk pelatihan dan validasi\n",
        "citra_latihan = data_latihan.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(100,150),\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "citra_validasi = data_latihan.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(100,150),\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "6Ps9agKa0mCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74209fd4-d75f-4817-f764-9691031a8e95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat model Sequential dan kompilasi\n",
        "**FINE TUNE THIS!**"
      ],
      "metadata": {
        "id": "pfmAvyV-4Ng_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the best model?\n",
        "# How many layers do we need?\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "mFbrekyr3hK0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINE CALLBACKS HERE**"
      ],
      "metadata": {
        "id": "ReZyaMmaA7W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    citra_latihan,\n",
        "    batch_size = 64,\n",
        "    epochs = 20,\n",
        "    callbacks = None,\n",
        "    validation_data = citra_validasi,\n",
        "    steps_per_epoch = 25,\n",
        "    validation_steps = 5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wfMCfuJA0yT",
        "outputId": "b3f1d210-07cf-43e8-a109-0eb280ecfc46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 14s 218ms/step - loss: 1.1368 - accuracy: 0.3831 - val_loss: 1.3625 - val_accuracy: 0.3313\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.9178 - accuracy: 0.5753 - val_loss: 0.7306 - val_accuracy: 0.6375\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.2768 - val_accuracy: 0.9250\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.3428 - accuracy: 0.8766 - val_loss: 0.2410 - val_accuracy: 0.9187\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 0.2857 - accuracy: 0.8925 - val_loss: 0.3620 - val_accuracy: 0.8687\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.2327 - accuracy: 0.9039 - val_loss: 0.2413 - val_accuracy: 0.9125\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 5s 215ms/step - loss: 0.2414 - accuracy: 0.9075 - val_loss: 0.2248 - val_accuracy: 0.9062\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.2320 - accuracy: 0.9286 - val_loss: 0.1533 - val_accuracy: 0.9312\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.2024 - accuracy: 0.9221 - val_loss: 0.2685 - val_accuracy: 0.9312\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.2146 - accuracy: 0.9377 - val_loss: 0.1114 - val_accuracy: 0.9563\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 5s 213ms/step - loss: 0.1720 - accuracy: 0.9403 - val_loss: 0.1931 - val_accuracy: 0.9375\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.1333 - accuracy: 0.9545 - val_loss: 0.0743 - val_accuracy: 0.9812\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.2438 - accuracy: 0.9195 - val_loss: 0.2416 - val_accuracy: 0.9375\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 5s 215ms/step - loss: 0.1736 - accuracy: 0.9351 - val_loss: 0.1202 - val_accuracy: 0.9688\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.1414 - accuracy: 0.9513 - val_loss: 0.1375 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.1354 - accuracy: 0.9494 - val_loss: 0.2288 - val_accuracy: 0.9125\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.1349 - accuracy: 0.9550 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.1210 - accuracy: 0.9649 - val_loss: 0.0789 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 6s 228ms/step - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.1330 - val_accuracy: 0.9937\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 0.1015 - accuracy: 0.9649 - val_loss: 0.1849 - val_accuracy: 0.9563\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0590058bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "th8weRATA6YP"
      }
    }
  ]
}